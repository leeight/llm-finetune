# 拓展阅读

读完本书之后，如果还想进一步学习大模型及训练相关知识，笔者推荐以下文献，其中的 arXiv 文献在「[幻觉翻译](https://hjfy.top)」上都有收录：

- Foundations of Large Language Models [^2501.09223]，一本大模型基础知识书，内容比较新。
- 大规模语言模型：从理论到实践 [^intro-llm]，全面介绍了大模型领域的相关基础知识。
- Reinforcement Learning: An Overview [^2412.05265]，强化学习基础知识。
- Alice's Adventures in a Differentiable Wonderland [^2404.17625]，神经网络基础知识。
- Neural Networks from Scratch in Python [^nnfs]，使用 Python 实现神经网络。
- The Ultra-Scale Playbook: Training LLMs on GPU Clusters [^Ultra-Scale]，覆盖了大规模模型训练所需的知识。
- A Survey of LLM x DATA [^2505.18458]，一篇关于大模型数据相关的综述，数据是大模型训练和微调的核心。

[^2501.09223]: <https://arxiv.org/abs/2501.09223>
[^2412.05265]: <https://arxiv.org/abs/2412.05265>
[^2505.18458]: <https://arxiv.org/abs/2505.18458>
[^2404.17625]: <https://arxiv.org/abs/2404.17625>
[^nnfs]: <https://nnfs.io/>
[^Ultra-Scale]: <https://huggingface.co/spaces/nanotron/ultrascale-playbook>
[^intro-llm]: <https://intro-llm.github.io/>
