<!DOCTYPE html>
<html lang="zh" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>前言 | 大模型微调与部署指南</title>
    <meta name="description" content="A VitePress site">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/llm-finetune/assets/style.CcTc65Li.css" as="style">
    <link rel="preload stylesheet" href="/llm-finetune/vp-icons.css" as="style">
    
    <script type="module" src="/llm-finetune/assets/app.B4ju1zUm.js"></script>
    <link rel="preload" href="/llm-finetune/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/llm-finetune/assets/chunks/theme.BxzAMCm1.js">
    <link rel="modulepreload" href="/llm-finetune/assets/chunks/framework.C1nslR49.js">
    <link rel="modulepreload" href="/llm-finetune/assets/intro.md.Qo0wVBT-.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"light",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-d8b57b2d><!--[--><!--]--><!--[--><span tabindex="-1" data-v-fcbfc0e0></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-fcbfc0e0>Skip to content</a><!--]--><!----><header class="VPNav" data-v-d8b57b2d data-v-7ad780c2><div class="VPNavBar" data-v-7ad780c2 data-v-9fd4d1dd><div class="wrapper" data-v-9fd4d1dd><div class="container" data-v-9fd4d1dd><div class="title" data-v-9fd4d1dd><div class="VPNavBarTitle has-sidebar" data-v-9fd4d1dd data-v-9f43907a><a class="title" href="/llm-finetune/" data-v-9f43907a><!--[--><!--]--><!--[--><img class="VPImage logo" src="./images/logo.png" alt data-v-ab19afbb><!--]--><span data-v-9f43907a>大模型微调与部署指南</span><!--[--><!--]--></a></div></div><div class="content" data-v-9fd4d1dd><div class="content-body" data-v-9fd4d1dd><!--[--><!--]--><div class="VPNavBarSearch search" data-v-9fd4d1dd><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">搜索</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-9fd4d1dd data-v-afb2845e><span id="main-nav-aria-label" class="visually-hidden" data-v-afb2845e> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/llm-finetune/" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>首页</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-9fd4d1dd data-v-3f90c1a5><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-3f90c1a5 data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-9fd4d1dd data-v-ef6192dc data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/nwind/llm-finetune" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-9fd4d1dd data-v-f953d92f data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-bfe7971f><span class="vpi-more-horizontal icon" data-v-bfe7971f></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><!----><!--[--><!--[--><!----><div class="group" data-v-f953d92f><div class="item appearance" data-v-f953d92f><p class="label" data-v-f953d92f>Appearance</p><div class="appearance-action" data-v-f953d92f><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-f953d92f data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div></div></div><div class="group" data-v-f953d92f><div class="item social-links" data-v-f953d92f><div class="VPSocialLinks social-links-list" data-v-f953d92f data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/nwind/llm-finetune" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-9fd4d1dd data-v-6bee1efd><span class="container" data-v-6bee1efd><span class="top" data-v-6bee1efd></span><span class="middle" data-v-6bee1efd></span><span class="bottom" data-v-6bee1efd></span></span></button></div></div></div></div><div class="divider" data-v-9fd4d1dd><div class="divider-line" data-v-9fd4d1dd></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-d8b57b2d data-v-2488c25a><div class="container" data-v-2488c25a><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-2488c25a><span class="vpi-align-left menu-icon" data-v-2488c25a></span><span class="menu-text" data-v-2488c25a>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-2488c25a data-v-6b867909><button data-v-6b867909>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-d8b57b2d data-v-42c4c606><div class="curtain" data-v-42c4c606></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-42c4c606><span class="visually-hidden" id="sidebar-aria-label" data-v-42c4c606> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0 has-active" data-v-51288d80 data-v-0009425e><!----><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/intro.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>前言</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/start.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>大模型微调入门</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/basic.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>大模型基础</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/sft.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>微调训练</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/rl.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>对齐训练</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/data.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>训练数据构造及管理</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/eval.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>评估</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/practice.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>微调实践</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/deploy.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>模型部署</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/appendix.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>附录</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/extend.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>拓展阅读</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-d8b57b2d data-v-9a6c75ad><div class="VPDoc has-sidebar has-aside" data-v-9a6c75ad data-v-e6f2a212><!--[--><!--]--><div class="container" data-v-e6f2a212><div class="aside" data-v-e6f2a212><div class="aside-curtain" data-v-e6f2a212></div><div class="aside-container" data-v-e6f2a212><div class="aside-content" data-v-e6f2a212><div class="VPDocAside" data-v-e6f2a212 data-v-cb998dce><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-cb998dce data-v-f610f197><div class="content" data-v-f610f197><div class="outline-marker" data-v-f610f197></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-f610f197>On this page</div><ul class="VPDocOutlineItem root" data-v-f610f197 data-v-53c99d69><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-cb998dce></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-e6f2a212><div class="content-container" data-v-e6f2a212><!--[--><!--]--><main class="main" data-v-e6f2a212><div style="position:relative;" class="vp-doc _llm-finetune_intro" data-v-e6f2a212><div><h1 id="前言" tabindex="-1">前言 <a class="header-anchor" href="#前言" aria-label="Permalink to &quot;前言&quot;">​</a></h1><p>ChatGPT 的诞生开启了大模型时代，各个行业都在探索如何利用大模型。早期的实践以提示词工程为主，通过优化提示词来提升模型表现。然而，人们逐渐发现大参数模型存在诸多局限性，并不适合所有应用场景，主要包括：</p><ul><li><strong>运行速度慢</strong>，完整输出通常需要十几秒。</li><li><strong>成本高昂</strong>，大参数模型需要多卡 GPU 部署，对显存要求高。尤其在当前国内无法通过正规渠道购买的情况下，价格居高不下，仅大型公司有能力采购。</li><li><strong>隐私难以保障</strong>，模型通常以 API 方式提供服务，需要将数据发送至第三方平台，存在泄露风险。</li></ul><p>因此，从 2023 年开始，小参数模型逐渐兴起。下图是来自 EPOCH AI 的统计数据：</p><p><img src="/llm-finetune/assets/large-scale-ai-models.BnBX36_y.png" alt="大模型统计"></p><p>可以看到，早期的大模型参数量普遍在 1000 亿以上，甚至出现了如 GLaM 这样拥有 1.2 万亿参数的模型。但从 2023 年开始，越来越多约 100 亿参数的模型开始涌现，小参数语言模型日益受到重视：</p><ul><li><strong>在开源模型领域</strong>，截至 2024 年 12 月，Hugging Face 网站上下载量最大的模型是 Qwen2.5-1.5B-Instruct，下载量达到 700 万（笔者认为其中可能不少是来自 vLLM 文档默认示例），而 Qwen2.5-72B-Instruct 模型的下载量只有 28 万。</li><li><strong>在闭源模型领域</strong>，ChatGPT 默认模型已经变成了 GPT-4o mini，虽然没有公布参数量，但从运行速度来看，肯定是小参数模型。</li></ul><p>虽然小参数模型运行成本较低，但其能力相对较弱。此时，提升能力的最佳方案是对模型进行微调，通过微调可以使小参数模型在特定领域的能力接近大参数模型的效果。</p><p>但微调需要对模型有一定了解，相较于提示词的门槛高很多，许多重要知识分布在论文及博客中，需要花费大量时间研究。本书将全面介绍微调相关知识，<strong>让没有深度学习经验的工程师也能微调垂直领域的大模型</strong>，分为以下几个章节：</p><ol><li><strong>大模型微调入门</strong>，分别使用大模型平台和本地工具对模型进行微调，让读者对微调有初步了解。</li><li><strong>大模型基础</strong>，介绍大模型底层实现原理及源码实现。</li><li><strong>微调训练基础</strong>，介绍微调相关的基础知识。</li><li><strong>训练数据构造</strong>，数据质量决定了模型效果，本章节将介绍各种构造训练数据的方法。</li><li><strong>效果评估</strong>，介绍如何自动化评估效果，现有的评估方法都有哪些局限性。</li><li><strong>微调实践</strong>，介绍各个垂直领域的微调实践，可以快速借鉴其中的经验。</li><li><strong>模型部署</strong>，介绍模型部署相关技术，如何降低成本和提升性能。</li></ol><p>本书不要求读者具备深度学习经验，但需要具备编程基础，最好了解 Python 和 Linux 的基础知识。</p><p>读者无需担心自己不懂算法。在大模型场景下，各个模型之间的差距较小，可微调的参数也不多，使得训练数据的质量成为最关键的因素。</p></div></div></main><footer class="VPDocFooter" data-v-e6f2a212 data-v-1bcd8184><!--[--><!--]--><div class="edit-info" data-v-1bcd8184><div class="edit-link" data-v-1bcd8184><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/nwind/llm-finetune/edit/main/intro.md" target="_blank" rel="noreferrer" data-v-1bcd8184><!--[--><span class="vpi-square-pen edit-link-icon" data-v-1bcd8184></span> Edit this page<!--]--></a></div><!----></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-1bcd8184><span class="visually-hidden" id="doc-footer-aria-label" data-v-1bcd8184>Pager</span><div class="pager" data-v-1bcd8184><!----></div><div class="pager" data-v-1bcd8184><a class="VPLink link pager-link next" href="/llm-finetune/start.html" data-v-1bcd8184><!--[--><span class="desc" data-v-1bcd8184>Next page</span><span class="title" data-v-1bcd8184>大模型微调入门</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"appendix.md\":\"EFrykACG\",\"basic.md\":\"Ce5ZVvFZ\",\"data.md\":\"89fWCx9d\",\"deploy.md\":\"CjPcg83d\",\"eval.md\":\"5Y2Fs_9V\",\"extend.md\":\"Brktvckt\",\"index.md\":\"DPGzQ56r\",\"intro.md\":\"Qo0wVBT-\",\"practice.md\":\"D_29NsGa\",\"rl.md\":\"BlQlHBfj\",\"sft.md\":\"CfmN7DXA\",\"start.md\":\"BJOPEC1V\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh\",\"dir\":\"ltr\",\"title\":\"大模型微调与部署指南\",\"description\":\"A VitePress site\",\"base\":\"/llm-finetune/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":{\"initialValue\":\"light\"},\"themeConfig\":{\"logo\":\"./images/logo.png\",\"nav\":[{\"text\":\"首页\",\"link\":\"/\"}],\"sidebar\":[{\"text\":\"\",\"items\":[{\"text\":\"前言\",\"link\":\"/intro.html\"},{\"text\":\"大模型微调入门\",\"link\":\"/start.html\"},{\"text\":\"大模型基础\",\"link\":\"/basic.html\"},{\"text\":\"微调训练\",\"link\":\"/sft.html\"},{\"text\":\"对齐训练\",\"link\":\"/rl.html\"},{\"text\":\"训练数据构造及管理\",\"link\":\"/data.html\"},{\"text\":\"评估\",\"link\":\"/eval.html\"},{\"text\":\"微调实践\",\"link\":\"/practice.html\"},{\"text\":\"模型部署\",\"link\":\"/deploy.html\"},{\"text\":\"附录\",\"link\":\"/appendix.html\"},{\"text\":\"拓展阅读\",\"link\":\"/extend.html\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/nwind/llm-finetune\"}],\"search\":{\"provider\":\"local\",\"options\":{\"translations\":{\"button\":{\"buttonText\":\"搜索\",\"buttonAriaLabel\":\"搜索\"},\"modal\":{\"displayDetails\":\"显示详细列表\",\"resetButtonTitle\":\"重置搜索\",\"backButtonTitle\":\"关闭搜索\",\"noResultsText\":\"没有结果\",\"footer\":{\"selectText\":\"选择\",\"selectKeyAriaLabel\":\"输入\",\"navigateText\":\"导航\",\"navigateUpKeyAriaLabel\":\"上箭头\",\"navigateDownKeyAriaLabel\":\"下箭头\",\"closeText\":\"关闭\",\"closeKeyAriaLabel\":\"esc\"}}}}},\"editLink\":{\"pattern\":\"https://github.com/nwind/llm-finetune/edit/main/:path\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>