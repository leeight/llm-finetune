<!DOCTYPE html>
<html lang="zh" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>微调实践 | 大模型微调与部署指南</title>
    <meta name="description" content="A VitePress site">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/llm-finetune/assets/style.CcTc65Li.css" as="style">
    <link rel="preload stylesheet" href="/llm-finetune/vp-icons.css" as="style">
    
    <script type="module" src="/llm-finetune/assets/app.B4ju1zUm.js"></script>
    <link rel="preload" href="/llm-finetune/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/llm-finetune/assets/chunks/theme.BxzAMCm1.js">
    <link rel="modulepreload" href="/llm-finetune/assets/chunks/framework.C1nslR49.js">
    <link rel="modulepreload" href="/llm-finetune/assets/practice.md.D_29NsGa.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"light",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-d8b57b2d><!--[--><!--]--><!--[--><span tabindex="-1" data-v-fcbfc0e0></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-fcbfc0e0>Skip to content</a><!--]--><!----><header class="VPNav" data-v-d8b57b2d data-v-7ad780c2><div class="VPNavBar" data-v-7ad780c2 data-v-9fd4d1dd><div class="wrapper" data-v-9fd4d1dd><div class="container" data-v-9fd4d1dd><div class="title" data-v-9fd4d1dd><div class="VPNavBarTitle has-sidebar" data-v-9fd4d1dd data-v-9f43907a><a class="title" href="/llm-finetune/" data-v-9f43907a><!--[--><!--]--><!--[--><img class="VPImage logo" src="./images/logo.png" alt data-v-ab19afbb><!--]--><span data-v-9f43907a>大模型微调与部署指南</span><!--[--><!--]--></a></div></div><div class="content" data-v-9fd4d1dd><div class="content-body" data-v-9fd4d1dd><!--[--><!--]--><div class="VPNavBarSearch search" data-v-9fd4d1dd><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">搜索</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-9fd4d1dd data-v-afb2845e><span id="main-nav-aria-label" class="visually-hidden" data-v-afb2845e> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/llm-finetune/" tabindex="0" data-v-afb2845e data-v-815115f5><!--[--><span data-v-815115f5>首页</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-9fd4d1dd data-v-3f90c1a5><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-3f90c1a5 data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-9fd4d1dd data-v-ef6192dc data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/nwind/llm-finetune" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-9fd4d1dd data-v-f953d92f data-v-bfe7971f><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-bfe7971f><span class="vpi-more-horizontal icon" data-v-bfe7971f></span></button><div class="menu" data-v-bfe7971f><div class="VPMenu" data-v-bfe7971f data-v-20ed86d6><!----><!--[--><!--[--><!----><div class="group" data-v-f953d92f><div class="item appearance" data-v-f953d92f><p class="label" data-v-f953d92f>Appearance</p><div class="appearance-action" data-v-f953d92f><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-f953d92f data-v-be9742d9 data-v-b4ccac88><span class="check" data-v-b4ccac88><span class="icon" data-v-b4ccac88><!--[--><span class="vpi-sun sun" data-v-be9742d9></span><span class="vpi-moon moon" data-v-be9742d9></span><!--]--></span></span></button></div></div></div><div class="group" data-v-f953d92f><div class="item social-links" data-v-f953d92f><div class="VPSocialLinks social-links-list" data-v-f953d92f data-v-e71e869c><!--[--><a class="VPSocialLink no-icon" href="https://github.com/nwind/llm-finetune" aria-label="github" target="_blank" rel="noopener" data-v-e71e869c data-v-60a9a2d3><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-9fd4d1dd data-v-6bee1efd><span class="container" data-v-6bee1efd><span class="top" data-v-6bee1efd></span><span class="middle" data-v-6bee1efd></span><span class="bottom" data-v-6bee1efd></span></span></button></div></div></div></div><div class="divider" data-v-9fd4d1dd><div class="divider-line" data-v-9fd4d1dd></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-d8b57b2d data-v-2488c25a><div class="container" data-v-2488c25a><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-2488c25a><span class="vpi-align-left menu-icon" data-v-2488c25a></span><span class="menu-text" data-v-2488c25a>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-2488c25a data-v-6b867909><button data-v-6b867909>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-d8b57b2d data-v-42c4c606><div class="curtain" data-v-42c4c606></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-42c4c606><span class="visually-hidden" id="sidebar-aria-label" data-v-42c4c606> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-51288d80><section class="VPSidebarItem level-0 has-active" data-v-51288d80 data-v-0009425e><!----><div class="items" data-v-0009425e><!--[--><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/intro.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>前言</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/start.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>大模型微调入门</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/basic.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>大模型基础</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/sft.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>微调训练</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/rl.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>对齐训练</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/data.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>训练数据构造及管理</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/eval.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>评估</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/practice.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>微调实践</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/deploy.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>模型部署</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/appendix.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>附录</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-0009425e data-v-0009425e><div class="item" data-v-0009425e><div class="indicator" data-v-0009425e></div><a class="VPLink link link" href="/llm-finetune/extend.html" data-v-0009425e><!--[--><p class="text" data-v-0009425e>拓展阅读</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-d8b57b2d data-v-9a6c75ad><div class="VPDoc has-sidebar has-aside" data-v-9a6c75ad data-v-e6f2a212><!--[--><!--]--><div class="container" data-v-e6f2a212><div class="aside" data-v-e6f2a212><div class="aside-curtain" data-v-e6f2a212></div><div class="aside-container" data-v-e6f2a212><div class="aside-content" data-v-e6f2a212><div class="VPDocAside" data-v-e6f2a212 data-v-cb998dce><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-cb998dce data-v-f610f197><div class="content" data-v-f610f197><div class="outline-marker" data-v-f610f197></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-f610f197>On this page</div><ul class="VPDocOutlineItem root" data-v-f610f197 data-v-53c99d69><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-cb998dce></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-e6f2a212><div class="content-container" data-v-e6f2a212><!--[--><!--]--><main class="main" data-v-e6f2a212><div style="position:relative;" class="vp-doc _llm-finetune_practice" data-v-e6f2a212><div><h1 id="微调实践" tabindex="-1">微调实践 <a class="header-anchor" href="#微调实践" aria-label="Permalink to &quot;微调实践&quot;">​</a></h1><p>本章将通过实例的方式介绍微调，包括简单的问答模型及业界著名模型的实践。</p><h2 id="基于-trl-和-lora-微调问答模型" tabindex="-1">基于 TRL 和 LoRA 微调问答模型 <a class="header-anchor" href="#基于-trl-和-lora-微调问答模型" aria-label="Permalink to &quot;基于 TRL 和 LoRA 微调问答模型&quot;">​</a></h2><p>除了前面提到的 LLaMA-Factory 工具，我们也可以基于 TRL 库实现 LoRA 微调。虽然目前功能不如 LLaMA-Factory 丰富，但已经包含了绝大部分常用功能。它的优点是 Hugging Face 官方支持，因此未来发展更稳定，贡献者数量也相对更多。</p><p>基于 TRL 实现微调的代码如下所示：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> peft </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LoraConfig</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> trl </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> SFTConfig, SFTTrainer</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> AutoModelForCausalLM</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> datasets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> load_dataset</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model_path </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;/path_to/Qwen2.5-0.5B&quot;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # 模型路径</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 加载模型和 tokenizer</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> AutoModelForCausalLM.from_pretrained(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model_path,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    use_cache</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # 关闭 KV 缓存，训练时不需要</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置 LoRA</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">peft_config </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LoraConfig(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    r</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">8</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 小矩阵的秩</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    lora_alpha</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">16</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 缩放比</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    inference_mode</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 关闭推理模式</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    target_modules</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;all-linear&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 训练哪些模块，推荐全部线性层</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    modules_to_save</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;lm_head&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;embed_token&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 默认不训练这两个模块，但加上可以提升效果</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    task_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;CAUSAL_LM&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 任务类型，目前大模型都是因果语言模型</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">output_dir </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;lora_output&quot;</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # 输出 LoRA 文件目录</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置微调参数，这里只列出部分参数，这些参数在微调训练一章有介绍</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">sft_config </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> SFTConfig(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    output_dir</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">output_dir,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 输出 LoRA 文件目录</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    max_seq_length</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4096</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 最大文本长度</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    per_device_train_batch_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 单个显卡上的批次大小</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    gradient_accumulation_steps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 梯度累积步数</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    optim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;adamw_torch&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 优化器</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    num_train_epochs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 训练轮数</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    save_steps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 保存步数</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    logging_steps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 日志步数</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    learning_rate</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3e-3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 学习率</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    bf16</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 使用 BF16 精度让训练更加稳定</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    warmup_ratio</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 预热比率</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    lr_scheduler_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;cosine&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 学习率调度器类型</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    gradient_checkpointing</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 梯度检查点，降低显存占用</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # packing=True,  # 将多个样本打包成一个样本，提升训练效率，但显存占用会变大</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # use_liger=True  # 使用 liger 内核优化，需要 pip install liger-kernel</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 加载训练数据</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> load_dataset(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;json&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">data_files</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;/path/to/zhihu_chatml.jsonl&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">split</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;train&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">trainer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> SFTTrainer(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    train_dataset</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">dataset,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    args</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">sft_config,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    peft_config</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">peft_config</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">trainer.train()  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 开始训练</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">trainer.save_model(output_dir)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 保存模型</span></span></code></pre></div><p>训练数据支持对话和补全两种格式，通常使用对话格式，因为它能支持多轮对话。数据格式类似如下文本的 JSONL 文件：</p><div class="language-txt vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">txt</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;法国首都在哪里？&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;...&quot;}]}</span></span>
<span class="line"><span>{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;谁写了《罗密欧与朱丽叶》？&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;...&quot;}]}</span></span></code></pre></div><p>训练数据我们使用 COIG-CQIA <a href="https://modelscope.cn/datasets/m-a-p/COIG-CQIA" target="_blank" rel="noreferrer">^CQIA</a>，它是一个开源高质量微调指令，来自零一万物、中科院深圳先进技术研究院和 M-A-P 等机构的研究者们，主要语言是中文。它由一个个 JSONL 文件组成，你可以只用其中的部分文件，我们以其中的知乎问答数据为例进行微调训练。</p><p>原始文件的每行是类似如下格式：</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;instruction&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;大学最冷门的专业有哪些？</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">最冷门的专业&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;input&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;output&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;1. 上海戏剧学院 木偶戏表演</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\n\n</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;task_type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">&quot;major&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;问答&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">&quot;minor&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;知乎问答&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]},</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;domain&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;通用&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;metadata&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;qid:67789453, aid:1048529303, tag:[]&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;answer_from&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;human&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;human_verified&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;copyright&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;暂无版权及作者信息&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>由于 TRL 中的数据格式要求与此不一致，我们需要写代码进行转换（需要使用 <code>pip install jsonlines</code> 安装 jsonlines 库）。</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sys</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jsonlines</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> []</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jsonlines.open(sys.argv[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> reader:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> reader:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        output.append({</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;messages&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;user&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: data[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;instruction&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;assistant&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: data[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;output&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            ]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        })</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">with</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jsonlines.open(sys.argv[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;w&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> writer:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    writer.write_all(output)</span></span></code></pre></div><p>然后就能使用下面的命令进行转换：</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">python</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> convert_to_chatml.py</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> zhihu.jsonl</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> zhihu_chatml.jsonl</span></span></code></pre></div><p>接着修改之前代码中的路径后训练即可。如果要多卡训练，可以安装 <code>accelerate</code> 库，先使用 <code>accelerate config</code> 来配置训练参数，然后使用 <code>accelerate launch</code> 来启动训练，比如：</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置多卡或多机环境</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">accelerate</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> config</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 启动训练，其它参数和前面一样</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">accelerate</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> launch</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> sft.py</span></span></code></pre></div><p>启动训练后会在训练 <code>logging_steps</code> 步数后打印日志，类似如下：</p><div class="language-txt vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">txt</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>{&#39;loss&#39;: 2.820, &#39;grad_norm&#39;: 0.71903, &#39;learning_rate&#39;: 0.00299, &#39;epoch&#39;: 0.47}</span></span>
<span class="line"><span>{&#39;loss&#39;: 2.555, &#39;grad_norm&#39;: 0.59527, &#39;learning_rate&#39;: 0.00284, &#39;epoch&#39;: 0.93}</span></span>
<span class="line"><span>{&#39;loss&#39;: 2.305, &#39;grad_norm&#39;: 0.86397, &#39;learning_rate&#39;: 0.00245, &#39;epoch&#39;: 1.37}</span></span>
<span class="line"><span>{&#39;loss&#39;: 2.144, &#39;grad_norm&#39;: 1.01672, &#39;learning_rate&#39;: 0.00190, &#39;epoch&#39;: 1.84}</span></span>
<span class="line"><span>{&#39;loss&#39;: 1.859, &#39;grad_norm&#39;: 1.15081, &#39;learning_rate&#39;: 0.00128, &#39;epoch&#39;: 2.28}</span></span>
<span class="line"><span>{&#39;loss&#39;: 1.521, &#39;grad_norm&#39;: 0.90571, &#39;learning_rate&#39;: 0.00069, &#39;epoch&#39;: 2.74}</span></span></code></pre></div><p>正常情况下 <code>loss</code> 应该逐步降低。如果发现没有明显降低甚至升高，那可能是学习率太低了，或者这个任务对模型太难了，需要调高学习率。最终 <code>loss</code> 降到多少比较合适取决于任务类型，简单的任务甚至能降到 <code>0.1</code> 以下。</p><p>训练之后的模型如何推理？可以参考本书的[使用 vLLM 进行推理]章节。在这个例子中，我们使用知乎问答训练，虽然数据量不大，但模型已经可以回答问题了，比如问「天空为什么是蓝色的？」，模型也能回答，下面是截取的部分回答：</p><div class="language-txt vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">txt</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>世界上有很多种原因可以解释天空为什么是蓝色的。一种简单的解释是，蓝色是光的原始波长。光是一种电磁波，它可以用光纤等传播。猫眼对蓝色光比较敏感，在光线很强的星云或恒星的周围更容易看到蓝色影像...</span></span></code></pre></div><p>可以看到这个 0.5B 的模型幻觉现象比较严重，想要训练好还需要大量数据和调参。</p><h2 id="通用问答模型-llama-3" tabindex="-1">通用问答模型 LLaMA 3 <a class="header-anchor" href="#通用问答模型-llama-3" aria-label="Permalink to &quot;通用问答模型 LLaMA 3&quot;">​</a></h2><p>LLaMA 3 在预训练基础上进行了 SFT 微调和 DPO 偏好优化，虽然它主要面向通用问答场景，但其中有许多可借鉴的方法。本节将介绍这些训练细节。</p><p>整个训练过程经过六轮迭代，每一轮都经过如下几个过程：</p><p><strong>训练「奖励模型」（Reward model）</strong>，这个奖励模型是使用如下步骤训练的：</p><ul><li>人工收集问题。</li><li>部署多个模型，每个模型都会对这个问题回答两次，得到两个答案。</li><li>人工标注这些回答的好坏，同时还支持人工对答案进行编辑，最终得到排序：人工编辑后的答案 &gt; 好的答案 &gt; 差的答案。</li><li>使用前面的标准来训练奖励模型。</li></ul><p><strong>SFT 微调</strong>，其中的训练数据由三部分组成：</p><ul><li>人工收集的问题，这些问题没有现成答案，所以先让模型生成多个答案，然后用「奖励模型」选择其中最好的答案，这一步也叫「拒绝采样」。</li><li>特定领域的合成数据，代码、数学、工具调用等，后面展开介绍。</li><li>人工编写的问题和答案。</li></ul><p>这里展开介绍一下合成数据，LLaMA 3 的合成数据主要有以下几种：</p><ul><li><strong>代码数据</strong>，这部分数据有 270 万，基于以下三种方式合成： <ul><li><strong>自然语言生成代码的数据合成</strong>，使用以下过程生成 100 万个编程对话数据： <ul><li><strong>生成问题描述</strong>，随机抽取代码片段，让模型生成针对这个代码片段的问题描述。</li><li><strong>生成代码</strong>，让模型生成代码。</li><li><strong>正确性分析</strong>，分析代码是否语法正确，让模型生成单元测试用例来执行。</li><li><strong>自我修正</strong>，如果前面出错，就让模型尝试自己修复。</li><li><strong>微调和迭代</strong>，用前面得到的数据对模型进行微调，然后下一轮使用这个微调后的模型再继续执行。</li></ul></li><li><strong>编程语言之间的转换</strong>，比如将 Python 代码转成 PHP，解决 PHP 代码较少的问题。</li><li><strong>反向翻译</strong>，要求模型基于代码生成解释，和第一种方式正好相反，这部分生成了 120 数据。</li></ul></li><li><strong>多语言数据</strong>，由四部分组成： <ul><li><strong>人工标注</strong>，这部分占比 2.4%。</li><li><strong>其它 NLP 任务数据</strong>，这部分占比 44.2%，比如 exams-qa 等公开数据。</li><li><strong>拒绝采样数据</strong>，这部分数据占比 18.8%，使用前面提到的「拒绝采样」方式挑选最好的回答，这里的不同之处是要保证语言一致性，比如中文问题应该用中文回答，哪怕对应的英文回答评分可能更高。</li><li><strong>翻译数据</strong>，使用机器翻译的文本。</li></ul></li><li><strong>工具调用</strong>，使用 Few-Shot 生成问题，然后生成对应的工具调用。</li><li><strong>数学推理</strong>、<strong>长文本</strong>，对大部分读者可能用处不大，这里就不展开了。</li></ul><p>合成数据在训练数据中占比 48%，提升了大模型在这些特殊领域上的能力。</p><p>后面我们会看到许多模型使用 GPT-4 生成微调数据，这种做法成本低但按 OpenAI 使用协议是不允许的，所以 LLaMA 3 使用迭代的方式来逐步提升模型能力，先用已有模型输出答案，对这个答案进行人工优化，然后训练新的模型，最后拿这个新模型输出答案并进行人工优化，整个过程进行了六轮迭代，人力成本很高，但它是一种很通用的做法。如果某个垂直领域下 GPT-4 效果很差或无法使用，我们就能使用类似 LLaMA 3 的迭代思路来生成微调数据。</p><p><strong>DPO 偏好对齐</strong>，在 SFT 微调之后，LLaMA 3 进行了 DPO 偏好优化，训练数据使用之前训练奖励模型时的排序，学习率是 1e-5，<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.025ex;" xmlns="http://www.w3.org/2000/svg" width="4.038ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 1785 705" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(895,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1256,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>b</mi><mi>e</mi><mi>t</mi><mi>a</mi></math></mjx-assistive-mml></mjx-container> 超参数是 0.1，除了 DPO 也试验过 PPO 训练，但发现 DPO 计算量小，效果也不错，所以就只用 DPO 了。</p><h2 id="苹果智能模型-afm" tabindex="-1">苹果智能模型 AFM <a class="header-anchor" href="#苹果智能模型-afm" aria-label="Permalink to &quot;苹果智能模型 AFM&quot;">​</a></h2><p>苹果智能模型 Apple Intelligence <a href="http://arxiv.org/abs/2407.21075" target="_blank" rel="noreferrer">^gunterAppleIntelligenceFoundation2024</a> 是 iPhone 16 上最大的改进，它由一个在手机上运行的 3B 参数量模型 AFM-on-device 和一个在服务器上部署的模型 AFM-server 组成，苹果罕见地公开了模型的预训练和微调细节，我们能从中学习许多经验。</p><p>模型整个训练过程如下图所示：</p><p><img src="/llm-finetune/assets/apple_intelligence_overview.Cx_9MB71.png" alt="苹果智能模型训练过程"></p><p>整个阶段包括：数据准备、数据预处理、预训练、后训练、优化部署，最后在手机上针对特定任务进行微调。</p><p>苹果智能模型的架构和 LLaMA 很相似，使用了 RMSNorm、GQA、RoPE 等方案，其中 AFM-on-device 的词表大小是 49k，AFM-server 的词表大小是 100k。</p><p>预训练文本的来源是：</p><ul><li><strong>网页数据</strong>，使用 Applebot 爬取，然后经过以下处理： <ul><li>使用 Safari 的阅读模型和 Boilerpipe <a href="https://dl.acm.org/doi/10.1145/1718487.1718542" target="_blank" rel="noreferrer">^kohlschutterBoilerplateDetectionUsing2010</a> 算法提取页面正文。</li><li>使用启发式和基于模型的分类器进行安全性和脏话过滤。</li><li>使用局部敏感的 n-gram 哈希进行全局模糊去重。</li><li>使用基于模型 <a href="http://arxiv.org/abs/2406.04638" target="_blank" rel="noreferrer">^kongLargeLanguageModelguided2024</a> <a href="http://arxiv.org/abs/2406.11794" target="_blank" rel="noreferrer">^liDataCompLMSearchNext2024</a> 的分类器进行质量过滤。</li><li>使用 4-13 gram 来过滤 811 个常见评测指标数据集。（主要是为了避免影响后续评测的可信度，这点可以看出苹果不在乎跑分，而是关注模型实际效果）</li></ul></li><li><strong>版权数据</strong>，从出版商获取，这些高质量的长文本数据主要用于扩充上下文训练。</li><li><strong>代码</strong>，从 Github 上根据开源协议过滤，包含 14 种常见语言，使用和网页数据类似的方法进行过滤。</li><li><strong>数学</strong>，包括来自网络的数学问答数据集，并基于特殊字符来自动识别网页中的数学内容，然后进行去重和清理。</li><li><strong>公开数据集</strong>，过滤其中的个人信息。</li></ul><p>预训练分为三个阶段：</p><ul><li><strong>核心阶段</strong>，混合所有文本，训练 token 数量是 6.3T，上下文长度是 4096。</li><li><strong>持续阶段</strong>，数据降低网页比例，增加代码和数据比例，训练 token 数量是 1T，上下文长度是 8192。</li><li><strong>长文本扩展阶段</strong>，混入长文本数据和合成的长文本数据，训练 token 数量是 100B，上下文长度是 327678。</li></ul><p>其中 AFM-server 使用 8192 个 TPUv4 芯片训练，而 AFM-on-device 是从 AFM-server 修剪后再使用相同训练数据蒸馏出来的，蒸馏使用 2048 个 TPUv5p 训练。</p><p>接下来是后训练，包括了指令微调 SFT 和人类对齐 RLHF。</p><p>SFT 数据包含以下两部分：</p><ul><li><strong>人工标注数据</strong>，从各种来源收集，建立了数据质量保障措施，包括人工评级、基于模型的自动过滤方法。</li><li><strong>合成数据</strong>，包括以下几部分： <ul><li><strong>数学问题</strong>，主要是依赖问题重写来基于现有问题生成新问题。</li><li><strong>工具使用</strong>，首先合成单一工具调用的例子，然后通过人工标准来改进调用多工具能力。</li><li><strong>编码</strong>，从 71 个不同编程主题的例子开始，让模型生成新问题，以及对应的代码和单元测试代码，通过执行单元测试来判断是否正确，得到 1.2 万个训练数据。</li></ul></li></ul><p>在指令微调方面，测试了多种混合比例的效果，对每种任务设置一个权重，通过不断调整权重来测试最终模型训练效果。</p><p>指令微调之后是基于强化学习的 RLHF 对齐，偏好对齐数据主要来自人工标注，评分标准包括：指令遵循、简洁性、真实性和无害性。</p><p>接下来是针对具体功能的微调，主要用于手机端，使用 LoRA 训练，每个任务训练一个单独的 LoRA，LoRA 微调影响所有线性层，对于 3B 模型，每个任务 LoRA 在 FP16 下只需十几 MB，适合动态加载。</p><p>比如摘要任务，用于手机上为邮件、消息通知提供摘要能力，这是一个单独的 LoRA，微调数据使用两步生成：</p><ul><li>从公共数据集、供应商及公司内部提交的示例中收集邮件、消息通知文本。</li><li>使用 AFM-server 基于前面的文本生成摘要，然后通过使用一个过滤器来过滤不适合的摘要，比如长度过长。</li></ul><p>对于摘要功能的评估使用人工评估，每个评分人员必须经过一系列资格培训，包括学士学位中写作相关内容，并在内部质量评测上表现良好。</p><p>摘要的评分标准使用以下几个维度，每个维度使用「好」、「一般」、「差」三个分数打分：</p><ul><li><strong>构成</strong>，评估摘要的整体可读性，考虑语法、标点、拼写和简洁性。</li><li><strong>全面性</strong>，评估摘要在捕捉要点或为用户指出任何行动、结论方面的全面性。</li><li><strong>贴切性</strong>，评估摘要与原始内容的贴切程度。不完全贴切的摘要可能包含夸张、推断、不准确或虚构的细节。</li><li><strong>遵循指示</strong>，评估摘要是否满足特定的风格和格式要求。要求针对每个功能量身定制，反映特定的产品和设计期望。</li><li><strong>有害性</strong>，评估摘要是否包含根据苹果公司的安全分类属于有害或不安全的内容。</li></ul><p>只要有一个维度是「差」，则整个摘要被标记为「差」，只有所有维度都是「好」，这个摘要才被标记为「好」。</p><p>最后在手机端的部署使用 4 位量化，甚至某些层还使用 2 位量化，不过 LoRA 依旧使用 FP16 来避免性能损失。</p><h2 id="深度思考模型-deepseek-r1" tabindex="-1">深度思考模型 DeepSeek-R1 <a class="header-anchor" href="#深度思考模型-deepseek-r1" aria-label="Permalink to &quot;深度思考模型 DeepSeek-R1&quot;">​</a></h2><p>OpenAI 的 o1 模型开启了新的模型性能提升方法，相当于内置了 CoT 功能，让模型通过大量思考来解决复杂问题，在数学和推理能力上有了显著提升。</p><p>不过 o1 模型并未披露训练细节，但最新的开源模型 DeepSeek-R1 在许多评测指标上都达到了 o1 的水平，因此我们可以通过它来了解如何训练一个类似效果的模型。</p><p>DeepSeek-R1 不仅在数学和推理方面表现优异，还很擅长解答模糊的问题，比如笔者使用很简单的提示词：「我要开发一款 AI 绘图软件，请帮忙写一份商业计划书」，模型给出的答案将近 2 千字，而且内容详实，效果超越了所有其它问答模型，下面是第一段的内容：</p><div class="language-markdown vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">markdown</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">## 1. 执行摘要</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> 项目名称：明确产品名称（如“ArtGenius AI”）。</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> 愿景：成为全球领先的 AI 创意工具，赋能个人与企业的视觉表达。</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> 核心价值：</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> 技术优势：基于自研/改进的扩散模型（Diffusion Model）或多模态模型，支持高精度图像生成与风格控制。</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> 差异化功能：例如“行业模板库”“实时协作设计”“3D 绘图融合”等独特功能。</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">  -</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> 用户体验：极简交互设计，降低非专业用户使用门槛。</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> 融资需求：初期计划融资 XXX 万元，用于技术研发、团队扩张与市场推广。</span></span></code></pre></div><p>因此 DeepSeek-R1 在许多场景下都很有价值，值得研究。</p><p>DeepSeek-R1 训练首先训练了一个完全用强化学习的模型 DeepSeek-R1-Zero，它和常见的 RLHF（Reinforcement Learning from Human Feedback）不同，它只有 RL（强化学习），没有 HF（人类反馈），这个训练不需要准备人类偏好数据，因为训练任务是有确定答案的代码生成和数学问题，可以很容易判断是否正确，因此这里的奖励模型只有准确性奖励，所以使用规则方式来判断，规则如下：</p><ol><li><strong>准确性奖励</strong>，如果是数学问题，直接判断答案是否正确；如果是代码问题，则使用单元测试来判断。</li><li><strong>格式奖励</strong>，判断输出过程有没有正确输出思考过程 <code>&lt;think&gt;</code> 和答案 <code>&lt;answer&gt;</code>。</li></ol><p>在 DeepSeek 的开源窗口里并没有这部分代码的具体实现，不过 Hugging Face 的 Open R1 项目提供了类似的实现，其中的数学校验和格式校验代码如下：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> math_verify </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> parse, verify</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> accuracy_reward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(completions, solution, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;检查生成的答案是否和标准答案一致&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    contents </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [completion[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> completion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> completions]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    rewards </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> []</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> content, sol </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> zip</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(contents, solution):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        try</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            answer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> parse(content)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            reward </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> float</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(verify(answer, parse(sol)))</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        except</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> Exception</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 如果解析失败，则返回 0</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            reward </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.0</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        rewards.append(reward)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 如果相同就是 1，否则是 0</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> rewards</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> format_reward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(completions, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;检查格式是否正确&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    pattern </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">^</span><span style="--shiki-light:#032F62;--shiki-dark:#DBEDFF;">&lt;think&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*?</span><span style="--shiki-light:#032F62;--shiki-dark:#DBEDFF;">&lt;/think&gt;&lt;answer&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">.</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*?</span><span style="--shiki-light:#032F62;--shiki-dark:#DBEDFF;">&lt;/answer&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">$</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    completion_contents </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [completion[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">][</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> completion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> completions]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    matches </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [re.match(pattern, content) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> content </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> completion_contents]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> match </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">else</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> match </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> matches]</span></span></code></pre></div><p>然后使用如下提示词模板来构造训练数据：</p><div class="language-txt vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">txt</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within &lt;think&gt; &lt;/think&gt; and &lt;answer&gt; &lt;/answer&gt; tags, respectively, i.e., &lt;think&gt; reasoning process here &lt;/think&gt; &lt;answer&gt; answer here &lt;/answer&gt;. User: {prompt}. Assistant:</span></span></code></pre></div><p>其中的 <code>{prompt}</code> 是用户的问题，让模型生成两部分内容，一个是思考阶段，用 <code>&lt;think&gt;</code> 标签包裹，另一个是答案，用 <code>&lt;answer&gt;</code> 标签包裹。</p><p>然后使用 GRPO 方法训练，可以通过调用 TRL 库来实现，将前面的函数传递进去，比如类似下面的代码：</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> datasets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> load_dataset</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> peft </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LoraConfig</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> trl </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> GRPOConfig, GRPOTrainer</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 加载问题集，这里只需要问题，不需要答案，类似下面的内容</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># {&quot;prompt&quot;: &quot;问题 1&quot;}</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># {&quot;prompt&quot;: &quot;问题 2&quot;}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">dataset </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> load_dataset(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;json&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">data_files</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;prompts.jsonl&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 训练参数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">training_args </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> GRPOConfig(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    output_dir</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Qwen2-0.5B-GRPO&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    learning_rate</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e-5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    logging_steps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    gradient_accumulation_steps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">16</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    max_completion_length</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">trainer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> GRPOTrainer(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Qwen/Qwen2-0.5B-Instruct&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 前面实现的奖励函数</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    reward_funcs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[accuracy_reward, format_reward],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    args</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">training_args,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    train_dataset</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">dataset,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    peft_config</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">LoraConfig(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">task_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;CAUSAL_LM&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">trainer.train()</span></span></code></pre></div><p>目前 LLaMA-Factory 及 torchtune 等训练库都不支持 GRPO 训练，因此只能使用上面的代码来实现。</p><p>不可思议的是，仅使用类似上面的简单代码，DeepSeek-R1-Zero 在数学和代码方面的评测就已经接近最强的 OpenAI o1 模型，而且包含了推理过程。这是一项重要发现，因为整个过程无需人工标注，成本很低，为什么之前没人发现？其实之前学术界做过类似尝试，但并不成功，可能是因为使用小模型效果不好，而 DeepSeek-R1-Zero 使用的 DeepSeek-V3-Base 参数量有 671B，这个基础模型在 AIME 2024 评测集上的初始成功率就有 15.6%，这或许是成功的关键。</p><p>但 DeepSeek-R1-Zero 有个问题是生成的推理过程可读性差，还会出现多种语言混合输出的情况，作者认为光靠强化学习难以解决这个问题，于是重新训练了新的模型 DeepSeek-R1，训练分为 4 个阶段：</p><p>一：冷启动阶段 SFT 微调</p><p>使用了多种方法生成初期微调数据，包括：</p><ul><li>使用 few-shot 长 CoT 示例作为提示词来让 DeepSeek-R1-Zero 生成思考过程。</li><li>使用 zero-shot 直接让 DeepSeek-R1-Zero 生成思考过程。</li><li>收集之前 DeepSeek-R1-Zero 训练数据中比较好的回答。</li><li>人工二次处理。</li></ul><p>通过这些方式收集了几千条数据，然后使用 SFT 对 DeepSeek-V3-Base 基础模型进行微调，得到第一个模型。</p><p>这个阶段得到了两个好处：</p><ol><li><strong>可读性增强</strong>，解决了 DeepSeek-R1-Zero 输出内容可读性差的问题。</li><li><strong>能力提升</strong>，训练后的性能优于 DeepSeek-R1-Zero。</li></ol><p>二：推理相关的强化学习</p><p>接下来针对数学和代码场景进行强化学习训练，这里和前面的 DeepSeek-R1-Zero 是一样的，不过奖励模型增加了对语言一致性的奖励，用于惩罚模型输出中英文混合的内容。</p><p>三：拒绝采样和 SFT 微调</p><p>这个阶段的主要目的是让模型具备回答通用问题的能力，训练数据分为两部分：</p><ul><li><strong>推理数据</strong>，使用拒绝采样方法来生成，这部分的推理数据不像前面数学和代码那样容易判断，因此是使用 DeepSeek-V3 模型进行评估，一共有 60 万微调数据。</li><li><strong>非推理的数据</strong>，主要是来自 DeepSeek-V3 的微调数据，一共有 20 万条。</li></ul><p>然后拿这 80 万条数据进行 SFT 微调，训练 2 epoch。</p><p>四：面向所有场景的强化学习</p><p>最后又进行了一次面向全场景的强化学习训练，这里的奖励方法分为两部分：</p><ul><li>对于能判断正确的问题，比如数学和代码，使用前面的规则方式判断。</li><li>对于没有唯一答案的其它问题，使用奖励模型来判断。</li></ul><p>以上就是 DeepSeek-R1 的训练过程，它的主要核心是多阶段训练，通过微调和强化学习来一步步提升模型能力，最终得到一个效果不错的模型。</p><h2 id="qwen2-5-中的后训练方法" tabindex="-1">Qwen2.5 中的后训练方法 <a class="header-anchor" href="#qwen2-5-中的后训练方法" aria-label="Permalink to &quot;Qwen2.5 中的后训练方法&quot;">​</a></h2><p>经过两年多的发展，Qwen 逐渐成为国内开放权重大模型的主流选择，包括前面提到的 DeepSeek-R1 的小模型蒸馏版本也是使用 Qwen 作为基础模型。本节将介绍 Qwen2.5 中的后训练方法。</p><p>Qwen2.5 的后训练分为 3 个阶段：SFT、DPO 和 GRPO。</p><p><strong>一：SFT 阶段</strong>，这个阶段的训练数据有 100 万条，使用 32K 上下文长度训练 2 轮，学习率从 7e-6 减小到 7e-7，裁剪超过 1.0 的梯度，训练数据包括如下几方面：</p><ul><li><strong>长序列生成</strong>，使用指令回译技术从预训练语料生成长文本查询指令，施加输出长度约束，并采用 Qwen2 进行低质量配对数据过滤。</li><li><strong>数学能力</strong>，引入 Qwen2.5-Math 思维链数据集，集成公共数据集、基础教育题库及合成问题等多源查询。通过拒绝采样与奖励模型协同机制，结合标注答案引导，构建高质量分步推理流程。</li><li><strong>代码能力</strong>，融合 Qwen2.5Coder 指令调优数据，采用多语言智能体协同框架，在近 40 种编程语言中生成多样化优质指令对。通过代码问答网站合成新样本及 GitHub 算法代码采集实现数据集扩展，并运用多语言沙盒环境进行静态代码检查与自动化单元测试验证，确保代码质量与正确性。</li><li><strong>指令遵循</strong>，建立代码验证框架，要求大模型同步生成指令与验证代码，配合单元测试进行交叉验证。基于执行反馈的拒绝采样机制严格筛选监督微调数据，确保模型对指令的精准遵循。</li><li><strong>结构化数据理解</strong>，构建涵盖传统任务（表格问答、事实验证、纠错解析）与复杂任务（结构化/半结构化数据处理）的综合性数据集。通过响应中嵌入推理链条，显著提升模型从结构化数据中提取信息的能力，实现多任务性能优化。</li><li><strong>逻辑推理</strong>，新增 7 万条跨领域查询指令，涵盖选择题、判断题及开放式问题。训练模型系统运用演绎推理、归纳概括、类比推理、因果推断及统计推理等方法。通过迭代优化机制筛除错误答案与瑕疵推理数据，持续强化逻辑推理精准度。</li><li><strong>跨语言迁移</strong>，采用翻译模型将高资源语言指令转化为多低资源语言变体，生成候选响应。通过语义对齐评估确保多语言响应与源语言版本在逻辑结构与风格特征上的一致性，维持跨语言表达的完整性。</li><li><strong>鲁棒性系统指令</strong>，构建数百条通用系统提示语以增强训练后多样性，确保系统提示与对话情境协调性。多提示评估表明模型保持优异性能且波动率降低，鲁棒性显著提升。</li><li><strong>响应筛选</strong>，建立多重自动标注体系，包含专用评判模型与多智能体协作评分系统。响应数据需通过严格质量评估，仅全系统一致认可的无瑕样本得以保留，确保输出质量符合最高标准。</li></ul><p><strong>二：DPO 阶段</strong>，这个阶段主要关注数学、编程、指令执行和逻辑推理等客观领域提示词，使用 SFT 生成不同答案，使用人工和自动化来检查结果，正确的作为正面实例，错误的作为负面实例，共构建了 15 万对偏好数据，然后使用 DPO 算法训练，学习率是 7e-7，最后使用 Online Merging Optimizers <a href="http://arxiv.org/abs/2405.17931" target="_blank" rel="noreferrer">^luOnlineMergingOptimizers2024</a> 方法来更新参数，减少对齐导致的损失。</p><p><strong>三：GRPO 阶段</strong>，这个阶段需要先训练奖励模型，提示词来自两个数据集：开源数据集和一个更为复杂的专有查询集，然后使用不同阶段的 Qwen 模型生成答案。</p><p>偏好排序使用人工或自动化标注，注意这里只提到了「自动化标注」，这类开放问题是没法用简单规则标准的，只能是大模型。如果只是使用 Qwen 2 模型进行标注，论文里肯定会说清楚，因此笔者猜测这里可能是用 GPT-4o 等其它模型来标注，没法明说，只好这样模糊地描述了。</p><p>标注的标准包括以下几部分：</p><ul><li><strong>真实性</strong>：回答必须基于事实的准确性，忠实反映提供的背景和指示。模型应避免生成虚假或没有数据支持的信息。</li><li><strong>有用性</strong>：模型的输出应真正有帮助，有效地解决用户的问题，同时提供积极、吸引人、具有教育意义且相关的内容。应准确遵循给定的指示，并为用户提供价值。</li><li><strong>简洁性</strong>：回答应简洁明了，避免不必要的冗长。目标是清晰有效地传达信息，而不让用户因过多细节而感到困扰。</li><li><strong>相关性</strong>：回答的所有部分应与用户的问题、对话历史和助手的上下文直接相关。模型应根据用户的需求和期望量身定制其输出，确保完全符合用户的要求。</li><li><strong>无害性</strong>：模型必须优先考虑用户安全，避免任何可能导致非法、不道德或有害行为的内容。它应始终促进道德行为和负责任的沟通。</li><li><strong>去偏见</strong>：模型应生成没有偏见的回答，包括但不限于性别、种族、国籍和政治。它应公平对待所有话题，遵循广泛接受的道德和伦理标准。</li></ul><p>有了偏好数据后线训练奖励模型，然后使用 GRPO 算法进行强化学习训练，每个提示词生成 8 个结果。</p><h2 id="真正开源模型-tulu-3-的实现细节" tabindex="-1">真正开源模型 Tulu 3 的实现细节 <a class="header-anchor" href="#真正开源模型-tulu-3-的实现细节" aria-label="Permalink to &quot;真正开源模型 Tulu 3 的实现细节&quot;">​</a></h2><p>前面提到的开源模型及大多数其它开源模型其实都不是真正开源，只能叫开放权重下载，因为它们都不提供相关的训练代码及数据，第三方开发者无法自己训练一个同样的模型。</p><p>虽然许多论文中会详细介绍实现细节，但文字说明难免产生歧义，不如代码清晰，目前真正代码和数据都开源的模型大部分是用于教学的小模型，只有 Tulu 3 <a href="http://arxiv.org/abs/2411.15124" target="_blank" rel="noreferrer">^lambertTulu3Pushing2024</a> 是具备一定竞争力的，它的部分评测指标达到了 GPT-4o Mini 的水平，因此有较大参考价值，本节将详细介绍它的训练细节。</p><p>Tulu 3 的关注后训练而不是预训练，这也是本书的重点，因为预训练模型目前已经很成熟，只需使用开放权重的模型即可。</p><p>Tulu 3 的后训练主要包括三阶段：SFT、DPO、RLVR，其中 RLVR 是 Tulu 3 中自创的强化学习方式，下面分别介绍。</p><h3 id="sft-微调训练阶段" tabindex="-1">SFT 微调训练阶段 <a class="header-anchor" href="#sft-微调训练阶段" aria-label="Permalink to &quot;SFT 微调训练阶段&quot;">​</a></h3><p>SFT 阶段的训练数据主要来自公开数据集和合成数据，只有 24 条手动创建的数据，这 24 条数据主要是用于回答身份，比如问你是什么模型，所有数据都能在 Hugging Face 上找到<a href="https://huggingface.co/collections/allenai/tulu-3-datasets-673b8df14442393f7213f372" target="_blank" rel="noreferrer">^tulu3_data</a>。</p><p>挑选公开数据集主要考虑这几方面：</p><ul><li><strong>多样性和高质量</strong>，选择了 WildChat 和 Open Assistant，因为它来自真实用户交互，还有 No Robots，因为它的数据全是人类标注的。</li><li><strong>特殊能力</strong>，主要是数学及代码相关的，来自 OpenMathInstruct 和 CodeAlpaca。</li><li><strong>来源及版权</strong>，只使用来源和版权清晰的数据，同时还区分了是否可商用。</li></ul><p>合成数据的提示词是使用 GPT-4o 结合 Persona Hub（在 [提升数据多样性] 一节中有介绍）来构造，包括数学、代码和指令跟随任务，以其中的代码为例，构造的提示词如下：</p><div class="language-txt vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">txt</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>{persona}</span></span>
<span class="line"><span>Assume you are the persona described above and you are asking a python programming question in stack overflow.</span></span></code></pre></div><p>其中的 persona 是角色描述，比如「A machine learning researcher focused on neural networks」，通过这种方式让大模型构造不同人可能会问的问题。</p><p>为了避免干扰后面的评估，这些数据集还通过 n-gram 等方式过滤掉和评估数据里类似的数据。</p><p>所有微调数据有 94 万条，使用方法是首先使用特殊任务的数据（比如数学和代码）来微调，然后不断融合其它类型的数据，并在训练过程中持续评估效果，如果效果下降就减少某种类型的数据量。</p><p>Tulu 3 还做了许多消融实验，得到以下经验：</p><ul><li><strong>数据多样性是有用的</strong>，如果去掉 WildChat 会导致大部分能力小幅下降。</li><li><strong>基础模型很重要</strong>，对于数学任务，如果使用的基础模型是 Qwen 2.5 Math 7B，微调后端的分数能赶上 LLaMA 3.1 70B 的分数，因此对于特殊领域的任务，继续预训练可以提升能力。</li><li><strong>不同模板之间有微小差别</strong>，如果将最后的换行符换成终止符，效果可以提升 0.2。</li><li><strong>随机种子对结果有微小影响</strong>，这也是为什么训练脚本的配置是 <code>--seed 123</code>，但这个属于玄学了。</li></ul><p>具体训练方法是自己基于 PyTorch 实现的，使用求和而不是取平均值，避免累计梯度计算的问题，这个问题在 [常见超参数说明] 一节中有介绍。</p><p>训练超参数尝试了多种学习率，发现 5e-6 效果最好，使用的轮次为 2，因为发现轮次 3 以上后效果持续下降。</p><h3 id="dpo-偏好训练阶段" tabindex="-1">DPO 偏好训练阶段 <a class="header-anchor" href="#dpo-偏好训练阶段" aria-label="Permalink to &quot;DPO 偏好训练阶段&quot;">​</a></h3><p>偏好训练的数据使用下面三阶段生成：</p><ol><li><strong>提示词选取</strong>，从 SFT 阶段的训练数据中挑选，还有部分未参与 SFT 训练的数据。</li><li><strong>生成答案</strong>，随机挑选 4 个大模型生成答案，包括 GPT-4o、LLaMA 3.1、Qwen 2.5 等，再使用前面 SFT 之后的 Tulu 3 模型生成一个答案。</li><li><strong>偏好标注</strong>，使用 GPT-4o 对答案从乐于助人、遵循指令、诚实和真实性四个方面打分 1-5 分，提示词较长这里不复述，可以查看原论文。</li></ol><p>偏好数据一共 35 万，使用 DPO 算法训练，除了原版算法，还测试了两个改进算法：SimPO 和 LN-DPO，发现 LN-DPO 效果最好，所以使用它，这个算法和原版的主要区别是结果除以输出文本长度，下面是两个公式对比：</p><mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-2.172ex;" xmlns="http://www.w3.org/2000/svg" width="51.25ex" height="5.475ex" role="img" focusable="false" viewBox="0 -1460 22652.7 2420" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="44" d="M130 622Q123 629 119 631T103 634T60 637H27V683H228Q399 682 419 682T461 676Q504 667 546 641T626 573T685 470T708 336Q708 210 634 116T442 3Q429 1 228 0H27V46H60Q102 47 111 49T130 61V622ZM593 338Q593 439 571 501T493 602Q439 637 355 637H322H294Q238 637 234 628Q231 624 231 344Q231 62 232 59Q233 49 248 48T339 46H350Q456 46 515 95Q561 133 577 191T593 338Z" style="stroke-width:3;"></path><path data-c="50" d="M130 622Q123 629 119 631T103 634T60 637H27V683H214Q237 683 276 683T331 684Q419 684 471 671T567 616Q624 563 624 489Q624 421 573 372T451 307Q429 302 328 301H234V181Q234 62 237 58Q245 47 304 46H337V0H326Q305 3 182 3Q47 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM507 488Q507 514 506 528T500 564T483 597T450 620T397 635Q385 637 307 637H286Q237 637 234 628Q231 624 231 483V342H302H339Q390 342 423 349T481 382Q507 411 507 488Z" transform="translate(764,0)" style="stroke-width:3;"></path><path data-c="4F" d="M56 340Q56 423 86 494T164 610T270 680T388 705Q521 705 621 601T722 341Q722 260 693 191T617 75T510 4T388 -22T267 3T160 74T85 189T56 340ZM467 647Q426 665 388 665Q360 665 331 654T269 620T213 549T179 439Q174 411 174 354Q174 144 277 61Q327 20 385 20H389H391Q474 20 537 99Q603 188 603 354Q603 411 598 439Q577 592 467 647Z" transform="translate(1445,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(2500.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3556.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(4501.2,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5779.2,0)"><path data-c="2061" d="" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(5945.9,0)"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z" style="stroke-width:3;"></path></g><g data-mml-node="mrow" transform="translate(6683.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(736,0)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1468.7,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(2746.7,0)"><path data-c="2061" d="" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(2913.3,0)"><g data-mml-node="mrow" transform="translate(457.9,710)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(603,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(984.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1373.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2452.9,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2730.9,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3302.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(603,-150) scale(0.707)"><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(392,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(836,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1460.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1849.5,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2928.8,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(3206.8,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3778.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><rect width="4367.8" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(7743.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(8743.6,0)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(9476.2,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(10754.2,0)"><path data-c="2061" d="" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(10920.9,0)"><g data-mml-node="mrow" transform="translate(457.9,710)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(603,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(984.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1373.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2157.4,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2435.4,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3007.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(603,-150) scale(0.707)"><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(392,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(836,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1460.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1849.5,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2633.2,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2911.2,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3483.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><rect width="4072.2" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(15233.1,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>DPO</mtext><mo>=</mo><mo>−</mo><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><mi>σ</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mi>β</mi><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mtext>ref</mtext></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>−</mo><mi>β</mi><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>l</mi></msub><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mtext>ref</mtext></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>l</mi></msub><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container><mjx-container tabindex="0" class="MathJax" jax="SVG" display="true" style="direction:ltr;display:block;text-align:center;margin:1em 0;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-2.172ex;" xmlns="http://www.w3.org/2000/svg" width="60.521ex" height="5.475ex" role="img" focusable="false" viewBox="0 -1460 26750.4 2420" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="4C" d="M128 622Q121 629 117 631T101 634T58 637H25V683H36Q48 680 182 680Q324 680 348 683H360V637H333Q273 637 258 635T233 622L232 342V129Q232 57 237 52Q243 47 313 47Q384 47 410 53Q470 70 498 110T536 221Q536 226 537 238T540 261T542 272T562 273H582V268Q580 265 568 137T554 5V0H25V46H58Q100 47 109 49T128 61V622Z" style="stroke-width:3;"></path><path data-c="4E" d="M42 46Q74 48 94 56T118 69T128 86V634H124Q114 637 52 637H25V683H232L235 680Q237 679 322 554T493 303L578 178V598Q572 608 568 613T544 627T492 637H475V683H483Q498 680 600 680Q706 680 715 683H724V637H707Q634 633 622 598L621 302V6L614 0H600Q585 0 582 3T481 150T282 443T171 605V345L172 86Q183 50 257 46H274V0H265Q250 3 150 3Q48 3 33 0H25V46H42Z" transform="translate(625,0)" style="stroke-width:3;"></path><path data-c="2D" d="M11 179V252H277V179H11Z" transform="translate(1375,0)" style="stroke-width:3;"></path><path data-c="44" d="M130 622Q123 629 119 631T103 634T60 637H27V683H228Q399 682 419 682T461 676Q504 667 546 641T626 573T685 470T708 336Q708 210 634 116T442 3Q429 1 228 0H27V46H60Q102 47 111 49T130 61V622ZM593 338Q593 439 571 501T493 602Q439 637 355 637H322H294Q238 637 234 628Q231 624 231 344Q231 62 232 59Q233 49 248 48T339 46H350Q456 46 515 95Q561 133 577 191T593 338Z" transform="translate(1708,0)" style="stroke-width:3;"></path><path data-c="50" d="M130 622Q123 629 119 631T103 634T60 637H27V683H214Q237 683 276 683T331 684Q419 684 471 671T567 616Q624 563 624 489Q624 421 573 372T451 307Q429 302 328 301H234V181Q234 62 237 58Q245 47 304 46H337V0H326Q305 3 182 3Q47 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM507 488Q507 514 506 528T500 564T483 597T450 620T397 635Q385 637 307 637H286Q237 637 234 628Q231 624 231 483V342H302H339Q390 342 423 349T481 382Q507 411 507 488Z" transform="translate(2472,0)" style="stroke-width:3;"></path><path data-c="4F" d="M56 340Q56 423 86 494T164 610T270 680T388 705Q521 705 621 601T722 341Q722 260 693 191T617 75T510 4T388 -22T267 3T160 74T85 189T56 340ZM467 647Q426 665 388 665Q360 665 331 654T269 620T213 549T179 439Q174 411 174 354Q174 144 277 61Q327 20 385 20H389H391Q474 20 537 99Q603 188 603 354Q603 411 598 439Q577 592 467 647Z" transform="translate(3153,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(4208.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5264.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(6209.2,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(7487.2,0)"><path data-c="2061" d="" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(7653.9,0)"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z" style="stroke-width:3;"></path></g><g data-mml-node="mrow" transform="translate(8391.6,0)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="28" d="M701 -940Q701 -943 695 -949H664Q662 -947 636 -922T591 -879T537 -818T475 -737T412 -636T350 -511T295 -362T250 -186T221 17T209 251Q209 962 573 1361Q596 1386 616 1405T649 1437T664 1450H695Q701 1444 701 1441Q701 1436 681 1415T629 1356T557 1261T476 1118T400 927T340 675T308 359Q306 321 306 250Q306 -139 400 -430T690 -924Q701 -936 701 -940Z" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(736,0)"><g data-mml-node="mi" transform="translate(754.6,676)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z" style="stroke-width:3;"></path></g><g data-mml-node="mrow" transform="translate(220,-709.5)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(278,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1357.3,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g></g><rect width="1835.3" height="60" x="120" y="220"></rect></g><g data-mml-node="mi" transform="translate(2811.3,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(4089.3,0)"><path data-c="2061" d="" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(4256,0)"><g data-mml-node="mrow" transform="translate(457.9,710)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(603,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(984.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1373.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2452.9,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2730.9,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3302.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(603,-150) scale(0.707)"><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(392,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(836,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1460.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1849.5,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2928.8,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(3206.8,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3778.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><rect width="4367.8" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(9086,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(10086.2,0)"><g data-mml-node="mi" transform="translate(606.9,676)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z" style="stroke-width:3;"></path></g><g data-mml-node="mrow" transform="translate(220,-709.5)"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(278,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1061.7,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g></g><rect width="1539.7" height="60" x="120" y="220"></rect></g><g data-mml-node="mi" transform="translate(11865.9,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" style="stroke-width:3;"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)" style="stroke-width:3;"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(13143.9,0)"><path data-c="2061" d="" style="stroke-width:3;"></path></g><g data-mml-node="mfrac" transform="translate(13310.6,0)"><g data-mml-node="mrow" transform="translate(457.9,710)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(603,-150) scale(0.707)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(984.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1373.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2157.4,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2435.4,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3007.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mrow" transform="translate(220,-710)"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z" style="stroke-width:3;"></path></g><g data-mml-node="mtext" transform="translate(603,-150) scale(0.707)"><path data-c="72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z" style="stroke-width:3;"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(392,0)" style="stroke-width:3;"></path><path data-c="66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z" transform="translate(836,0)" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1460.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(1849.5,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2633.2,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2911.2,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3483.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g><rect width="4072.2" height="60" x="120" y="220"></rect></g><g data-mml-node="mo" transform="translate(17622.8,0) translate(0 -0.5)"><path data-c="29" d="M34 1438Q34 1446 37 1448T50 1450H56H71Q73 1448 99 1423T144 1380T198 1319T260 1238T323 1137T385 1013T440 864T485 688T514 485T526 251Q526 134 519 53Q472 -519 162 -860Q139 -885 119 -904T86 -936T71 -949H56Q43 -949 39 -947T34 -937Q88 -883 140 -813Q428 -430 428 251Q428 453 402 628T338 922T245 1146T145 1309T46 1425Q44 1427 42 1429T39 1433T36 1436L34 1438Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="block" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;overflow:hidden;width:100%;"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>LN-DPO</mtext><mo>=</mo><mo>−</mo><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><mi>σ</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mfrac><mi>β</mi><mrow><mo data-mjx-texclass="ORD" stretchy="false">|</mo><msub><mi>y</mi><mi>w</mi></msub><mo data-mjx-texclass="ORD" stretchy="false">|</mo></mrow></mfrac><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mtext>ref</mtext></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo>−</mo><mfrac><mi>β</mi><mrow><mo data-mjx-texclass="ORD" stretchy="false">|</mo><msub><mi>y</mi><mi>l</mi></msub><mo data-mjx-texclass="ORD" stretchy="false">|</mo></mrow></mfrac><mi>log</mi><mo data-mjx-texclass="NONE">⁡</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>l</mi></msub><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><mtext>ref</mtext></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>l</mi></msub><mo data-mjx-texclass="ORD" stretchy="false">|</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container><p>除了 DPO 还尝试了 PPO 算法，PPO 算法的效果和 DPO 差不多，但 PPO 计算成本高，用 2 个节点运行 PPO 耗时 28 小时，而 1 个节点运行 DPO 只需 4 小时。</p><p>作者认为 PPO 还可以通过调参优化性能，但由于资源和时间限制没做。</p><h3 id="rlvr-强化学习训练阶段" tabindex="-1">RLVR 强化学习训练阶段 <a class="header-anchor" href="#rlvr-强化学习训练阶段" aria-label="Permalink to &quot;RLVR 强化学习训练阶段&quot;">​</a></h3><p>最后一个阶段是使用强化学习训练容易验证结果的能力，这些任务包括：</p><ul><li>数学问题，包括 GSM8K 及 MATH 的训练数据。</li><li>指令遵循问题，来自 SFT 数据，验证返回结果是否符合格式。</li></ul><p>这些问题可以通过是否正确来判断，如果正确就返回 10，错误返回 0，训练算法使用 DPO，作者做了许多实验，得到以下经验：</p><ul><li>RLVR 可以提升目标领域的分数。</li><li>价值模型使用奖励模型初始化的效果好于使用 SFT 模型初始化，这个也是通常的做法。</li><li>使用奖励模型计算奖励的效果还不如使用正确性判断，因此训练时去掉了奖励模型。</li><li>使用 RLVR 训练 SFT 模型和 DPO 模型都能得到相似结果，但使用 DPO 模型在测试集上的表现更好。</li></ul><p>整体来说 Tulu 3 的强化学习训练比较务实，只用可验证的问题进行训练，这个阶段和 DeepSeek-R1-Zero 的做法是类似的，只是用的基础模型和算法不同。</p><h2 id="自然语言生成-sql-codes-模型" tabindex="-1">自然语言生成 SQL CodeS 模型 <a class="header-anchor" href="#自然语言生成-sql-codes-模型" aria-label="Permalink to &quot;自然语言生成 SQL CodeS 模型&quot;">​</a></h2><p>自然语言查询数据可以让不会 SQL 的用户也能通过查询数据库，这是一个很实用的功能，因此是大模型研究的热门领域之一。</p><p>本节将介绍 CodeS <a href="http://arxiv.org/abs/2402.16347" target="_blank" rel="noreferrer">^liCodeSBuildingOpensource2024</a>，它通过微调开源模型来实现自然语言生成 SQL，其中许多做法值得参考，而且微调了 1B 到 15B 大小的模型，可以用来比较不同模型的效果。</p><p>CodeS 使用 StarCoder 作为基础模型，考虑到在这个模型的训练数据中 SQL 占比很小，作者对它进行了继续预训练，数据由三部分组成：</p><ul><li>11G SQL 数据（来自 StarCoder）。</li><li>6G 自然语言到代码的数据（来自 CoNaLa、CodeAlpaca-20k 等），作者还从开源代码中使用正则提取出 SELECT 语句，抽取了 45 万个 SQL 语句，然后使用 GPT-3.5 来生成对应的自然语言，期望通过这些数据让模型更好了解自然语言和 SQL 的关系。</li><li>4.5G 自然语言对话的数据（来自 Alpaca、Unnatural-instructions 和 UltraChat）。</li></ul><p>接着使用这些文本数据依次对 StarCoder 的 1B、3B、7B 和 15B 模型进行了继续预训练，其中 SQL 数据训练了两轮，另外两个数据训练一轮。</p><p>增量训练使用全参数微调，使用 DeepSpeed Zero-3 来训练，1B、3B、7B 和 15B 模型的训练时间是 1.5、3、8 和 16 天（论文中没有说明，但测试用的是 8 卡 NVIDIA A800，训练可能也是用这个）。</p><p>微调训练主要使用 Spider，使用 GPT-3.5 做了数据增强，主要是几步：</p><ul><li>收集一些真实用户问题，并手工编写这些问题对应的 SQL。</li><li>根据表结构、示例数据和现有问题，让 GPT-3.5 生成新的问题。</li><li>让 GPT-3.5 根据这个问题生成 SQL。</li></ul><p>同时还使用模板的方式来合成问题，比如下面问题以及对应的 SQL：</p><div class="language-markdown vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">markdown</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">## 问题模板</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Return the lowest {COLUMN} of {TABLE}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">## 对应的 SQL 模板</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">SELECT {COLUMN} FROM {TABLE} GROUP BY {COLUMN} ORDER BY COUNT (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">\*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) ASC LIMIT 1</span></span></code></pre></div><p>使用这个模板就能基于现有表结构批量替换来生成问题和 SQL，作者还使用 GPT-3.5 扩充了类似的模板对。</p><p>由于数据库中通常包含大量表和字段，容易超出提示词上下文长度限制，因此使用了模式过滤器来选择最相关的 N 个表和列，同时还对数据库里的值进行检索，方法是使用 Lucene 进行索引，然后根据问题找出数据库里最相关的值。</p><p>最终在提示词由如下几部分组成：</p><ul><li>用户问题。</li><li>使用 RESDSQL <a href="http://arxiv.org/abs/2302.05965" target="_blank" rel="noreferrer">^liRESDSQLDecouplingSchema2023</a> 的方法训练了个分类器，通过它根据用户问题找出最相关的 N 个表和列，并将这些列的类型、字段名、注释、值信息提取出来，还有表的主键和外键。</li><li>根据用户问题找出数据库里最相关的值。</li></ul><p>下面是一个示例：</p><div class="language-txt vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">txt</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Database prompt:</span></span>
<span class="line"><span>table movie , columns = [ movie.mid ( int | primary key | comment : movie id | values : 101 , 102 ) , movie.title ( text | values : Gone with the Wind , Star Wars )]</span></span>
<span class="line"><span>table reviewer , columns = [ reviewer.rid ( int | primary key | comment : reviewer id | values : 201 , 202 ) , reviewer.name ( text | values : Sarah Martinez , Daniel Lewis )]</span></span>
<span class="line"><span>table rating , columns = [ rating.rid ( int | comment : reviewer id | values : 201 , 202 ) , rating.mid ( int | comment : movie id | values : 101 ,106 ) , rating.stars ( int | comment : rating stars | values : 2 , 4 )]</span></span>
<span class="line"><span></span></span>
<span class="line"><span>foreign keys :</span></span>
<span class="line"><span>rating.rid = reviewer.rid</span></span>
<span class="line"><span>rating.mid = movie.mid</span></span>
<span class="line"><span></span></span>
<span class="line"><span>matched values :</span></span>
<span class="line"><span>reviewer.name ( Sarah Martinez )</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Question:</span></span>
<span class="line"><span>What are the names of all directors whose movies have been reviewed by Sarah Martinez?</span></span></code></pre></div><p>其中 <code>Database prompt</code> 部分是筛选出来的表及字段信息，每个字段取其中两个值作为示例，<code>foreign keys</code> 是外键信息，<code>matched values</code> 是根据问题找出相关的值，<code>Question</code> 是用户问题。</p><p>最终效果如下，首先是不微调直接测试继续预训练模型 Few-Shot 的效果，其中 EX（execution accuracy）是指执行结果相同的正确率，但结果相同可能只是碰巧，TS（test-suite accuracy）通过测试多个数据库来避免这种情况，但 BIRD 数据集不支持 TS，所以还是使用 EX 作为测试结果。</p><table tabindex="0"><thead><tr><th>模型</th><th>Spider TS 准确率</th><th>BIRD EX 准确率</th></tr></thead><tbody><tr><td>StarCoderBase-1B</td><td>48.6</td><td>22.69</td></tr><tr><td>StarCoderBase-3B</td><td>60.8</td><td>36.31</td></tr><tr><td>StarCoderBase-7B</td><td>64.6</td><td>40.61</td></tr><tr><td>StarCoderBase-15B</td><td>70.0</td><td>41.20</td></tr><tr><td>Llama2-13B</td><td>47.6</td><td>25.36</td></tr><tr><td>CodeS-1B</td><td>59.1</td><td>31.03</td></tr><tr><td>CodeS-3B</td><td>69.7</td><td>41.85</td></tr><tr><td>CodeS-7B</td><td>71.8</td><td>44.26</td></tr><tr><td>CodeS-15B</td><td>73.4</td><td>45.44</td></tr></tbody></table><p>从这个测试结果可以得到以下几个结论：</p><ul><li>StarCoder 相对 Llama 2 在生成 SQL 方面更有优势，1B 模型就能达到 13B 的效果，这也是 CodeS 选择基于它的原因。</li><li>经过继续预训练后的 CodeS 模型分数有提升，尤其是 1B 和 3B 的小模型提升明显。</li></ul><p>接着是微调后的效果：</p><table tabindex="0"><thead><tr><th>模型</th><th>Spider TS 准确率</th><th>BIRD EX 准确率</th></tr></thead><tbody><tr><td>SQL-PaLM</td><td>82.8</td><td>78.2</td></tr><tr><td>DAIL-SQL (GPT-4)</td><td>83.6</td><td>76.2</td></tr><tr><td>SFT Llama2-7B</td><td>77.8</td><td>73.0</td></tr><tr><td>SFT Llama2-13B</td><td>81.6</td><td>76.6</td></tr><tr><td>SFT CodeS-1B</td><td>77.9</td><td>72.2</td></tr><tr><td>SFT CodeS-3B</td><td>83.4</td><td>78.1</td></tr><tr><td>SFT CodeS-7B</td><td>85.4</td><td>80.3</td></tr><tr><td>SFT CodeS-15B</td><td>84.9</td><td>79.4</td></tr></tbody></table><p>其中 SQL-PaLM <a href="http://arxiv.org/abs/2306.00739" target="_blank" rel="noreferrer">^sunSQLPaLMImprovedLarge2023</a> 是 Google 基于 PaLM 微调的模型，它的参数量有 54B，DAIL-SQL (GPT-4) 是基于 GPT-4 使用多种工程方法优化后的方案，SFT Llama2-7B 是使用 Llama 2 微调后的模型。</p><p>通过这个微调结果可以得到以下结论：</p><ul><li>微调后的 1B 模型就能达到 GPT-4 简单使用 Few-Shot 的效果。</li><li>微调后的 7B 模型超过了 GPT-4 提示词优化的效果。</li><li>3B 模型的效果不太差，部署性价比最高，反而是 15B 模型还不如 7B 模型。</li></ul><p>总结一下，这个模型微调实践有许多可以借鉴的经验：</p><ul><li>做继续预训练对效果有帮助，尤其是参数量小的模型。</li><li>要善于利用 GPT-3.5 来扩充数据，包括问题及模板。</li><li>模型参数量大效果不一定好，比如 PaLM 参数量有 54B，效果还不如作者微调的 3B 模型，所以最好测试多种参数量的效果。</li></ul><h2 id="自然语言生成-sql-的难点细节" tabindex="-1">自然语言生成 SQL 的难点细节 <a class="header-anchor" href="#自然语言生成-sql-的难点细节" aria-label="Permalink to &quot;自然语言生成 SQL 的难点细节&quot;">​</a></h2><p>前面介绍了 CodeS 的微调实践，但它主要是针对 Spider 数据集的实践，这个数据集相对简单，在真实业务场景下还会面临许多其它问题。本节将结合笔者的经验进一步展开讨论，通过这个例子来让读者了解大模型应用落地的实际困难，对其它垂直领域也有借鉴意义。</p><p>难点一：表名和字段名通常是英文。</p><p>最著名的自然语言生成 SQL 训练数据是 Spider <a href="http://arxiv.org/abs/1809.08887" target="_blank" rel="noreferrer">^yuSpiderLargeScaleHumanLabeled2019</a>，目前在这个训练数据下最高准确率可以达到 91.2%，但这个测试集是英文，英文的优势是用户问的名词和 SQL 字段几乎一样，比如用户问题是「List the name of clubs」，对应的 SQL 就是「SELECT name FROM club」。</p><p>但我们要做的是中文查询 SQL，在数据库中极少有人用中文字段名，前面的例子就变成了「列出俱乐部名称」，这时大模型不仅要正确切分句子，还要根据中文找英文。</p><p>这导致在中文场景下准确率会明显下降，比如 Spider 对应的中文测试集 CSpider <a href="http://arxiv.org/abs/1909.13293" target="_blank" rel="noreferrer">^minPilotStudyChinese2019</a> 最高准确率只有 62%。</p><p>要解决这个问题必须给大模型提供中英文对照信息，比如我们可以在上下文中用注释告诉大模型字段中文是什么，类似下面的例子：</p><div class="language-sql vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sql</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">CREATE</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> table</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> &quot;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">club</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&quot; (</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;name&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> VARCHAR</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">255</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) COMMENT </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;名称&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>训练数据里多些这样的例子就能让大模型学会中英文对照。</p><p>难点二：类型字段通常使用数字而不是中文。</p><p>数据库中还会出现枚举类型的字段，比如支付方式，在数据库里可能存的是 0 和 1，对应微信和支付宝，但用户问的时候肯定是中文，比如「查询微信支付的比例」，这时就要转成对应的数值。</p><p>同样可以通过注释的方式告诉大模型，比如下面的例子：</p><div class="language-sql vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sql</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">CREATE</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> TABLE</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> &quot;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">order</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&quot; (</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;pay_type&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> COMMENT </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;支付方式：0 代表微信、1 代表支付宝&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>要做到这点一方面需要在训练数据里增加类似例子，另一方面在对接实际表结构时，需要让用户能补充字段值对应的中文信息。</p><p>难点三：需要动态关联值。</p><p>前面提到枚举类型字段是固定的，可以通过注释可以告诉大模型，但有时值可能是动态的，比如「查询我上个月的销量」，这里的「我」是谁？或者「查询部门上个月的销量」，这里的部门也需要关联到对应的人。</p><p>这个问题无法直接通过训练解决，因为训练时数据都是固定的，要解决这个问题需要从两方面解决：</p><ul><li>训练模型在遇到这种情况是输出特殊值，比如 <code>&lt;current_user&gt;</code>。</li><li>在查询引擎上做特殊处理，对这些特殊值进行自动转换，比如查询 <code>user_id = &#39;&lt;current_user&gt;&#39;</code> 要转成查当前登录用户的 id。</li></ul><p>难点四：需要猜测字段。</p><p>前面提到的例子用户问题中明确提到了字段，但实际场景下用户很可能会省略字段，比如「查询苹果手机的总销量」，而不是「查询<strong>商品名称</strong>中包含苹果手机的总销量」，忽略了商品名称这个字段名，这时需要根据值推测查询哪个字段，并且判断是用等于查询还是模糊查询，由于在表结构定义里并没有值信息，导致难以正确判断。</p><p>要解决这个问题可以在提示词里加几个表数据示例，训练大模型推测字段的能力，但这类数据不好准备。</p><p>难点五：上下文窗口问题。</p><p>类似 Spider 的测试集通常表结构都比较简单，只有个位数的表，每个表的字段数量也不超过十个，但在真实场景下许多系统超过 100 张表，比如微软某个内部财务数据中心有 632 张表，200 个视图，总共超过 7400 列 <a href="https://www.cidrdb.org/cidr2024/papers/p74-floratou.pdf" target="_blank" rel="noreferrer">^floratouNL2SQLSolvedProblem2024</a>，如果都放在上下文窗口里很容易就超过大模型上下文窗口限制。</p><p>这里我们做个简单分析，比如类似下面的表结构：</p><div class="language-sql vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sql</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">-- 博客表</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">CREATE</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> TABLE</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> &quot;</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">blog</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&quot; (</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;id&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;title&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> text</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> COMMENT </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;标题&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;body&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> text</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> COMMENT </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;内容&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;created_at&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> datetime</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> COMMENT </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;创建时间&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;author_id&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> COMMENT </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;作者id&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">);</span></span></code></pre></div><p>用 LLaMA 3 算一下需要 51 个 token，实际表字段至少是这个是两倍，也就是 102 个 token，如果有 50 个表就需要 5k token，再加上示例很容易就超过 8K 的窗口大小限制。而我们还需要给输出留出至少 1K token。</p><p>这个问题是不是随着大模型升级能解决了呢？最近两年大模型上下文窗口得到了显著提升，但内容变多后准确率也下降了，比如 LLaMA 3.1 虽然支持 128K 窗口，但有人测试过它在 4K 内下的准确率是 96.5，到了 64K 就降低为 88.4，到了 128K 就降低为 66.6 [^hsiehRULERWhatsReal2024]。</p><p>那是否可以通过向量数据库来减少窗口大小呢？虽然看起来可以，但用于训练句子嵌入模型的文本对和表结构描述差异较大，向量搜索准确率可能不高。</p><p>难点六：大模型时间观差。</p><p>大模型训练时通常没有包括时间，这也是大模型幻觉的根源之一，训练的时候并不知道某个文本到底是什么时间的，因为知识重在变化，将这些知识混在一起训练会导致大模型无法区分哪些是过时的信息。</p><p>你可以试试问大模型上个月的这周一是几年几月几号，这种问题需要精确计算，大模型并不擅长。</p><p>而在数据查询中我们经常需要查询「上个月的销量是多少」，这种任务要如何训练呢？可以尝试的方法是在训练提示词里写出今天的日期，比如「今天是 2024 年 6 月 28 日」，然后期望大模型能自动找出规律，生成类似 <code>DATE_FORMAT(date, &#39;%Y-%m&#39;) = &#39;2024-07&#39;</code> 的过滤条件。</p><p>但这样做有三个问题：</p><ul><li>训练效果不好保证，需要构造大量时间示例来避免大模型只是记住特例而不是找到规律。</li><li>有些问题需要真正懂时间计算，难以训练，比如「上周」并不能像「上个月」那样能通过简单数学计算得出。</li><li>时间函数 SQL 有方言问题，前面的例子是 MySQL 下的写法，如果是 ClickHouse 要用 <code>formatDateTime</code> 函数，如果是 DB2 要用 <code>VARCHAR_FORMAT</code> 函数、Oracle 和 Postgres 要用 <code>to_char</code> 函数、SQLServer 要用 <code>DATEPART</code> 和 <code>CONCAT</code> 函数组合才能实现，如果要支持多种数据库，难道要所有方言都训一遍？这将导致训练数据成倍膨胀，也导致大模型更容易幻觉。</li></ul><p>如何解决？推荐的办法是直接在引擎内部解决，大模型只需要生成 <code>date = &#39;上个月&#39;</code>，当引擎发现左侧条件是个日期类型字段，就会转成对应方言的日期函数调用，避免了大模型难以计算时间和方言问题，但缺点是必须完整枚举所有可能的时间特殊值。</p><p>除了前面提到的相对时间，引擎还可以实现自动识别常见日期格式，比如数据库里存的是日期时间字段，在查询 <code>date = &#39;2024&#39;</code> 时，查询引擎会自动转成 <code>YEAR(date) = &#39;2024&#39;</code>，同样也简化了模型训练。</p><p>难点七：数据库方言问题。</p><p>前面提到了方言问题，除了时间函数之外还有其它方言问题，比如 MySQL 的字段要用反引号包裹，以及 LIMIT 写法常见的就有 10 种，还有大量你可能不知道的语法限制，比如 Oracle 不支持 <code>GROUP BY 1</code> 这种写法，你必须将这个 1 展开为 SELECT 里对应的字段。</p><p>这个问题要怎么解决？有两个方案：</p><ul><li>训练时上下文增加数据库信息，并训练多种方言的写法，但这样做一方面会大量增加训练数据，另一方面容易导致模型幻觉，使用错误的方言。</li><li>利用查询引擎解决，比如统一使用 LIMIT 语法，针对不同方言生成对应的写法，比如使用 Trino 查询引擎。</li></ul><p>难点八：关联关系可能有多种情况。</p><p>虽然 SQL 数据库都叫关系型数据库，但在表结构中并没有关系配置，而是靠查询的时候动态关联关系，比如要多对多查询就要增加一个中间表，然后 JOIN 两个表。</p><p>由于表结构中没有这样的信息，导致只能猜测关系，比如有作者 <code>author</code> 和地址 <code>address</code> 两个表，它们之间如果是一对一关系，有时我们会在作者表中加个 <code>address_id</code> 字段，也可以在 <code>address</code> 表中加个 <code>author_id</code> 字段，看起来很容易判断？然而在真实场景下通常不会那么规范，比如作者表中的地址字段可能叫 <code>addr_id</code>，地址表中的作者字段可能又叫 <code>owner_id</code>，难以进行简单匹配。</p><p>这种信息缺失将降低大模型准确率，因此我们需要补上这个信息，增加类似 ORM 框架里的关系定义，在注释中提供这些信息：</p><div class="language-java vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">CREATE TABLE </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;author&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;id&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;address_id&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> text COMMENT </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;one-to-one: address.id&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">);</span></span></code></pre></div><p>然后训练大模型如何根据这些关系来生成代码。</p><p>难点九：单个 SQL 不能解决所有问题。</p><p>目前所有自然语言查询 SQL 的训练都是文本和 SQL 一对一匹配，但这并不能解决所有问题，比如「查询班级和对应的学生，只返回 10 个班级」，这种情况需要两次或者 N+1 次查询。</p><p>另外有些数据库不支持窗口函数，这时要实现相同功能就要用代码来实现组内配置，因此有些问题难以通过单个 SQL 解决。</p><p>这个问题怎么解决？单靠大模型训练很难解决。</p><p>难点十：专业知识。</p><p>比如查询「蛋白水平高于正常的患者」，这里的「正常」就是一种垂直领域的专业知识，大模型必须有这方面的专业知识才能正确回答。</p><p>难点十一：安全性问题。</p><p>如果生成 SQL 后直接调用还会带来安全性问题，包括：</p><ul><li>SQL 安全，用户可能直接问一句「删掉所有数据」。</li><li>访问权限，数据访问需要权限控制，比如只能查询自己部门的数据。</li><li>数据隐私，前面提到为了提升效果我们需要将几条真实数据放在提示词中，如果使用大模型 API 还可能导致数据泄露。</li></ul><p>解决前两个问题需要对生成的 SQL 做解析和分析，解析具体查询了哪个表及字段，这样才能做行列级别权限控制，避免越权。</p><p>最后一个问题可以尝试动态脱敏，或私有化部署大模型。</p><p>难点十二：自然语言的歧义。</p><p>除了前面提到的大模型幻觉问题，还有个更难的问题是自然语言本身的歧义特性，比如「查询用户名为空」的数据，这个空到底是指 IS NULL、还是空字符串、还是用户名是真的叫「空」？类似的歧义问题很常见，甚至有分析称通过人工标注发现 KaggleDBQA 中 41% 是有歧义的 <a href="https://www.cidrdb.org/cidr2024/papers/p74-floratou.pdf" target="_blank" rel="noreferrer">^floratouNL2SQLSolvedProblem2024</a>。</p><p>怎么解决？无解，只要是基于自然语言的技术都不可能解决，因为语言就是无法准确表示，这个道理两千多年前的思想家就意识到了：</p><blockquote><p>道可道，非常道；名可名，非常名。-《道德经》</p><p>佛说某某，即非某某，是名某某。-《金刚经》</p></blockquote><p>这是大模型应用落地面临的最大问题，只能通过产品机制缓解，比如输出界面让用户确认是否符合预期。</p><h2 id="其它微调实践中的数据构造方法" tabindex="-1">其它微调实践中的数据构造方法 <a class="header-anchor" href="#其它微调实践中的数据构造方法" aria-label="Permalink to &quot;其它微调实践中的数据构造方法&quot;">​</a></h2><p>从前面分析的经验可以看出，构造训练数据是微调实践中最重要的工作，因此本节将介绍许多实际应用中的数据构造方法。</p><h3 id="淘宝用户检索问题改写-beque" tabindex="-1">淘宝用户检索问题改写 BEQUE <a class="header-anchor" href="#淘宝用户检索问题改写-beque" aria-label="Permalink to &quot;淘宝用户检索问题改写 BEQUE&quot;">​</a></h3><p>BEQUE 是淘宝在搜索领域的大模型应用，主要用于改写长尾用户问题。该系统已经在淘宝上线，改写了 0.34% 的用户问题，整体 GMV 提升了 0.4%。</p><p>模型的主要功能是将不常见的用户问题改成更常见的商品名称，从而提升检索效果。例如，用户输入「自建盲盒」，搜索引擎无法找到相关产品，但如果改写成「DIY 盲盒」，就能找到。</p><p>开发者通过以下三种方式构建数据：</p><ul><li><strong>上一代系统里的改写数据</strong>：之前开发过类似功能的系统，因此使用了之前较好的改写示例作为初始训练数据。</li><li><strong>从日志中挖掘</strong>：抽取了 2000 万条日志，包括三方面内容： <ul><li>人工标记某个搜索的改写是否合适，作为质量判断任务。</li><li>根据用户点击来判断，如果用户点击了某个商品，就认为用户输入的问题与该商品相关性强，作为标题预测任务。</li><li>基于大模型用 CoT 来解释查询重写的思考过程。</li></ul></li><li><strong>人工重写</strong>：共生成了 15 万条数据。</li></ul><h3 id="教育大模型-taoli" tabindex="-1">教育大模型 Taoli <a class="header-anchor" href="#教育大模型-taoli" aria-label="Permalink to &quot;教育大模型 Taoli&quot;">​</a></h3><p>数据构造基于 500 余册国际中文教育教材与教辅书、汉语水平考试试题以及汉语学习者词典等，构建了 8.8 万条教育领域的问答数据。这些数据包括：</p><ul><li>语法改错数据集 YACLC。</li><li>释义数据，基于字典生成，例如使用字典中的例句，然后反问「“因”在此上下文中的具体含义是什么？」。</li><li>简化复杂句子数据集 MCTS。</li><li>汉语国际教育动态语料库。</li></ul><h3 id="医疗问答大模型-meerkat" tabindex="-1">医疗问答大模型 Meerkat <a class="header-anchor" href="#医疗问答大模型-meerkat" aria-label="Permalink to &quot;医疗问答大模型 Meerkat&quot;">​</a></h3><p>Meerkat 的训练数据由三部分组成：</p><ul><li>在 MedQA 数据集基础上，使用 GPT-4 补充增加 CoT 推理过程，这个数据集称为 MedQA-Cot。</li><li>基于 18 本医学教科书生成 78K 数据，这个数据集称为 MedBooks-Cot-18。</li><li>其他公开数据集，包括 MedMCQA、LiveQA、MedicationQA、AlpaCare 等。</li></ul><h3 id="金融模型-cfgpt" tabindex="-1">金融模型 CFGPT <a class="header-anchor" href="#金融模型-cfgpt" aria-label="Permalink to &quot;金融模型 CFGPT&quot;">​</a></h3><p>CFGPT 是专门针对中文金融领域的大模型，能够用于金融场景的问答。它收集了大量预训练和指令数据。</p><p>预训练数据集包括 5.91 亿份文档和 1930 亿个 token，分为六个子数据集：</p><ul><li>CFData-CP（6.24%）：包括 3900 份公司招股说明书，共计 130 亿个 token。</li><li>CFData-CA（12.28%）：包括 600 万份公司公告，共计 170 亿个 token。</li><li>CFData-RR（2.51%）：包括 39.2 万份研究报告，共计 30 亿个 token。</li><li>CFData-FN（18.70%）：包括 8200 万份财经新闻，共计 260 亿个 token。</li><li>CFData-SM（60.15%）：包括 4.95 亿份社交媒体内容，共计 840 亿个 token。</li><li>CFData-Wiki（0.09%）：包括 25.5 万份维基百科内容，共计 1.37 亿个 token。</li></ul><p>其中 CFData-CP、CFData-CA 和 CFData-RR 主要是 PDF 格式，使用 PDFMiner 转换成文本格式，并使用正则去掉文档中的所有图形、表格和乱码，过滤掉小于 1000 字符的文档。其余三个数据源为网页数据，使用 HTML 解析器提取。由于这部分数据质量较差，因此进行了敏感词过滤，敏感词来自 PanGu-<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.439ex;" xmlns="http://www.w3.org/2000/svg" width="5.509ex" height="2.009ex" role="img" focusable="false" viewBox="0 -694 2435 888" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(529,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(827,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1330,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1906,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>a</mi><mi>l</mi><mi>p</mi><mi>h</mi><mi>a</mi></math></mjx-assistive-mml></mjx-container>，而维基百科还将繁体中文转成简体，并对这些文档使用 LSH 算法进行去重。</p><p>SFT 指令有 150 万条，通过 6 种不同方式构建：</p><ul><li>CFData-SA（5.69%）：12 万个，是情感分析任务，使用了两种方法构建： <ul><li>使用 GPT-4 标注社交媒体中的文本内容为正面、负面或中立。</li><li>使用 CFData-RR 研究报告中的内容和投资评级，将这些评级转换成正面、负面和中立。</li></ul></li><li>CFData-RS（50.60%）：36.9 万个，基于 CFData-RR 研究报告中的正文和摘要，让模型根据正文生成摘要。</li><li>CFData-ED（22.69%）：49 万个，是金融事件分类任务，来自 CN-Fin 数据集。</li><li>CFData-TD（12.37%）：36.9 万个，基于 CFData-RR 研究报告中的主题，也是一种分类任务。</li><li>CFData-QA（0.39%）：1.2 万个，金融领域的问答，这部分训练数据是基于英文问答数据 FinQA 和 ConvFinQA 翻译成中文。</li><li>CFData-SP（8.27%）：21.2 万个，股票价格预测任务，使用社交媒体和新闻来预测次日的股票价格是上涨、下跌还是持平。</li></ul><p>CFGPT 的做法是将文本数据转成不同指令任务，以摘要为例，对应的提示词如下：</p><div class="language-txt vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">txt</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Please summarize the following financial report. The report is “[report]”.</span></span></code></pre></div><p>通过类似这样的方式构建了大量训练指令，类似于前面介绍过的[从文本中构造问答]。</p></div></div></main><footer class="VPDocFooter" data-v-e6f2a212 data-v-1bcd8184><!--[--><!--]--><div class="edit-info" data-v-1bcd8184><div class="edit-link" data-v-1bcd8184><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/nwind/llm-finetune/edit/main/practice.md" target="_blank" rel="noreferrer" data-v-1bcd8184><!--[--><span class="vpi-square-pen edit-link-icon" data-v-1bcd8184></span> Edit this page<!--]--></a></div><!----></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-1bcd8184><span class="visually-hidden" id="doc-footer-aria-label" data-v-1bcd8184>Pager</span><div class="pager" data-v-1bcd8184><a class="VPLink link pager-link prev" href="/llm-finetune/eval.html" data-v-1bcd8184><!--[--><span class="desc" data-v-1bcd8184>Previous page</span><span class="title" data-v-1bcd8184>评估</span><!--]--></a></div><div class="pager" data-v-1bcd8184><a class="VPLink link pager-link next" href="/llm-finetune/deploy.html" data-v-1bcd8184><!--[--><span class="desc" data-v-1bcd8184>Next page</span><span class="title" data-v-1bcd8184>模型部署</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"appendix.md\":\"EFrykACG\",\"basic.md\":\"Ce5ZVvFZ\",\"data.md\":\"89fWCx9d\",\"deploy.md\":\"CjPcg83d\",\"eval.md\":\"5Y2Fs_9V\",\"extend.md\":\"Brktvckt\",\"index.md\":\"DPGzQ56r\",\"intro.md\":\"Qo0wVBT-\",\"practice.md\":\"D_29NsGa\",\"rl.md\":\"BlQlHBfj\",\"sft.md\":\"CfmN7DXA\",\"start.md\":\"BJOPEC1V\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh\",\"dir\":\"ltr\",\"title\":\"大模型微调与部署指南\",\"description\":\"A VitePress site\",\"base\":\"/llm-finetune/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":{\"initialValue\":\"light\"},\"themeConfig\":{\"logo\":\"./images/logo.png\",\"nav\":[{\"text\":\"首页\",\"link\":\"/\"}],\"sidebar\":[{\"text\":\"\",\"items\":[{\"text\":\"前言\",\"link\":\"/intro.html\"},{\"text\":\"大模型微调入门\",\"link\":\"/start.html\"},{\"text\":\"大模型基础\",\"link\":\"/basic.html\"},{\"text\":\"微调训练\",\"link\":\"/sft.html\"},{\"text\":\"对齐训练\",\"link\":\"/rl.html\"},{\"text\":\"训练数据构造及管理\",\"link\":\"/data.html\"},{\"text\":\"评估\",\"link\":\"/eval.html\"},{\"text\":\"微调实践\",\"link\":\"/practice.html\"},{\"text\":\"模型部署\",\"link\":\"/deploy.html\"},{\"text\":\"附录\",\"link\":\"/appendix.html\"},{\"text\":\"拓展阅读\",\"link\":\"/extend.html\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/nwind/llm-finetune\"}],\"search\":{\"provider\":\"local\",\"options\":{\"translations\":{\"button\":{\"buttonText\":\"搜索\",\"buttonAriaLabel\":\"搜索\"},\"modal\":{\"displayDetails\":\"显示详细列表\",\"resetButtonTitle\":\"重置搜索\",\"backButtonTitle\":\"关闭搜索\",\"noResultsText\":\"没有结果\",\"footer\":{\"selectText\":\"选择\",\"selectKeyAriaLabel\":\"输入\",\"navigateText\":\"导航\",\"navigateUpKeyAriaLabel\":\"上箭头\",\"navigateDownKeyAriaLabel\":\"下箭头\",\"closeText\":\"关闭\",\"closeKeyAriaLabel\":\"esc\"}}}}},\"editLink\":{\"pattern\":\"https://github.com/nwind/llm-finetune/edit/main/:path\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>